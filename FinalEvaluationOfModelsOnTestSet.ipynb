{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34a1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pathlib\n",
    "import random\n",
    "import cv2\n",
    "import gc\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "import solt as sl\n",
    "import solt.transforms as slt\n",
    "import sklearn.model_selection as ms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c671aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91673622",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8013d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    list_preds = []\n",
    "    list_labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
    "            counter += 1\n",
    "            \n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass.\n",
    "            outputs = model(image)\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # Calculate the accuracy.\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            valid_running_correct += (preds == labels).sum().item()\n",
    "            list_preds.append(preds)\n",
    "            list_labels.append(labels)\n",
    "            \n",
    "            \n",
    "    \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    epoch_loss = valid_running_loss / counter\n",
    "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
    "    \n",
    "    #for balanced accuracy\n",
    "    list_true = []\n",
    "    for i in range(len(list_labels)):\n",
    "        for j in range(0, list_labels[i].shape[0]):\n",
    "            list_true.append(int(list_labels[i][j]))\n",
    "\n",
    "    list_pred = []\n",
    "    for i in range(len(list_preds)):\n",
    "        for j in range(0, list_preds[i].shape[0]):\n",
    "            list_pred.append(int(list_preds[i][j]))\n",
    "            \n",
    "    balanced_acc = balanced_accuracy_score(list_true, list_pred)\n",
    "    return epoch_loss, epoch_acc, balanced_acc, list_true, list_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb923707",
   "metadata": {},
   "source": [
    "### Model 1: DataSubset + EfficientNet_b4\n",
    "Loading model with highest Validation BACC: epoch 38 -> model_checkpoint_37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd1ef523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform_1(pretrained=True):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "        transforms.Resize((380, 380)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize_transform()\n",
    "    ])\n",
    "    return train_transform\n",
    "\n",
    "\n",
    "# Validation transforms\n",
    "def get_valid_transform_1(pretrained=True):\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.Resize((380, 380)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize_transform()\n",
    "    ])\n",
    "    return valid_transform\n",
    "\n",
    "def get_datasets_1(pretrained=True):\n",
    "    dataset_test_valTF = datasets.ImageFolder(\n",
    "        base_path+\"/data/test\", \n",
    "        transform=(get_valid_transform_1(pretrained=True))\n",
    "    )\n",
    "    \n",
    "    dataset_test_trainTF = datasets.ImageFolder(\n",
    "        base_path+\"/data/test\", \n",
    "        transform=(get_train_transform_1(pretrained=True))\n",
    "    )\n",
    "    return dataset_test_valTF, dataset_test_trainTF\n",
    "\n",
    "\n",
    "def get_data_loaders_1(dataset_test_valTF, dataset_test_trainTF, BATCH_SIZE=8):\n",
    "    test_loader_valTF  = DataLoader(dataset_test_valTF, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader_trainTF  = DataLoader(dataset_test_trainTF, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return test_loader_valTF, test_loader_trainTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34120b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_valTF_1, dataset_test_trainTF_1 = get_datasets_1(True)\n",
    "test_loader_valTF_1, test_loader_trainTF_1 = get_data_loaders_1(dataset_test_valTF_1, dataset_test_trainTF_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea6e8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_1 = base_path+f\"/efficientnet_b4_dup_subsetData/model_checkpoint_{37}.pt\"\n",
    "model_1 = torch.load(PATH_1, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b81d9fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,008,909 total parameters.\n",
      "460,293 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params_1 = sum(p.numel() for p in model_1.parameters())\n",
    "print(f\"{total_params_1:,} total parameters.\")\n",
    "total_trainable_params_1 = sum(\n",
    "    p.numel() for p in model_1.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params_1:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca592913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [02:51<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_1a, accuracy_1a, balanced_acc_1a, list_true_1a, list_pred_1a = validate(model_1, test_loader_valTF_1, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "583f474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [04:03<00:00,  5.28s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_1b, accuracy_1b, balanced_acc_1b, list_true_1b, list_pred_1b = validate(model_1, test_loader_trainTF_1, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c618287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cks_1a = cohen_kappa_score(list_true_1a, list_pred_1a)\n",
    "cks_1b = cohen_kappa_score(list_true_1b, list_pred_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "752eee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Only Resizing of images\n",
      " Test loss: 1.444\n",
      " Test acc: 30.601\n",
      " Test BACC: 0.272\n",
      " Cohen-Kappa: 0.105\n",
      "With Training Image preprocessing\n",
      " Test loss: 1.456\n",
      " Test acc: 30.328\n",
      " Test BACC: 0.272\n",
      " Cohen-Kappa: 0.107\n"
     ]
    }
   ],
   "source": [
    "print(f\"With Only Resizing of images\\n Test loss: {loss_1a:.3f}\\n Test acc: {accuracy_1a:.3f}\\n Test BACC: {balanced_acc_1a:.3f}\\n Cohen-Kappa: {cks_1a:.3f}\")\n",
    "print(f\"With Training Image preprocessing\\n Test loss: {loss_1b:.3f}\\n Test acc: {accuracy_1b:.3f}\\n Test BACC: {balanced_acc_1b:.3f}\\n Cohen-Kappa: {cks_1b:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b827efb",
   "metadata": {},
   "source": [
    "### Model 2: Baseline 1\n",
    "##### EfficientNet_b0 + Linear Classification Layer\n",
    "Loading model with highest Validation BACC: epoch 17 -> model_checkpoint_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5de33559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform_2(pretrained=True):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize_transform()\n",
    "    ])\n",
    "    return train_transform\n",
    "\n",
    "\n",
    "# Validation transforms\n",
    "def get_valid_transform_2(pretrained=True):\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize_transform()\n",
    "    ])\n",
    "    return valid_transform\n",
    "\n",
    "def get_datasets_2(pretrained=True):\n",
    "    dataset_test_valTF = datasets.ImageFolder(\n",
    "        base_path+\"/data/test\", \n",
    "        transform=(get_valid_transform_2(pretrained=True))\n",
    "    )\n",
    "    \n",
    "    dataset_test_trainTF = datasets.ImageFolder(\n",
    "        base_path+\"/data/test\", \n",
    "        transform=(get_train_transform_2(pretrained=True))\n",
    "    )\n",
    "    return dataset_test_valTF, dataset_test_trainTF\n",
    "\n",
    "\n",
    "def get_data_loaders_2(dataset_test_valTF, dataset_test_trainTF, BATCH_SIZE=8):\n",
    "    test_loader_valTF  = DataLoader(dataset_test_valTF, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader_trainTF  = DataLoader(dataset_test_trainTF, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return test_loader_valTF, test_loader_trainTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbc1e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_valTF_2, dataset_test_trainTF_2 = get_datasets_2(True)\n",
    "test_loader_valTF_2, test_loader_trainTF_2 = get_data_loaders_2(dataset_test_valTF_2, dataset_test_trainTF_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff2bd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_2 = base_path+f\"/baseline_1/model_checkpoint_{16}.pt\"\n",
    "model_2 = torch.load(PATH_2, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64bdd96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,013,953 total parameters.\n",
      "6,405 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params_2 = sum(p.numel() for p in model_2.parameters())\n",
    "print(f\"{total_params_2:,} total parameters.\")\n",
    "total_trainable_params_2 = sum(\n",
    "    p.numel() for p in model_2.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params_2:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fade233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [01:12<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_2a, accuracy_2a, balanced_acc_2a, list_true_2a, list_pred_2a = validate(model_2, test_loader_valTF_2, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c45e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [04:12<00:00,  5.49s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_2b, accuracy_2b, balanced_acc_2b, list_true_2b, list_pred_2b = validate(model_2, test_loader_trainTF_2, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "693a3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "cks_2a = cohen_kappa_score(list_true_2a, list_pred_2a)\n",
    "cks_2b = cohen_kappa_score(list_true_2b, list_pred_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "902d89b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Only Resizing of images\n",
      " Test loss: 0.614\n",
      " Test acc: 77.596\n",
      " Test BACC: 0.515\n",
      " Cohen-Kappa: 0.633\n",
      "With Training Image preprocessing\n",
      " Test loss: 0.602\n",
      " Test acc: 78.415\n",
      " Test BACC: 0.533\n",
      " Cohen-Kappa: 0.645\n"
     ]
    }
   ],
   "source": [
    "print(f\"With Only Resizing of images\\n Test loss: {loss_2a:.3f}\\n Test acc: {accuracy_2a:.3f}\\n Test BACC: {balanced_acc_2a:.3f}\\n Cohen-Kappa: {cks_2a:.3f}\")\n",
    "print(f\"With Training Image preprocessing\\n Test loss: {loss_2b:.3f}\\n Test acc: {accuracy_2b:.3f}\\n Test BACC: {balanced_acc_2b:.3f}\\n Cohen-Kappa: {cks_2b:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92564e8e",
   "metadata": {},
   "source": [
    "### Model 3: RandomWeightSampler + EfficientNet_b4\n",
    "Loading model with highest Validation BACC: epoch 18 -> model_checkpoint_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad4a577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform_3(pretrained=True):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "        transforms.Resize((380, 380)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize_transform()\n",
    "    ])\n",
    "    return train_transform\n",
    "\n",
    "\n",
    "def get_valid_transform_3(pretrained=True):\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.Resize((380, 380)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize_transform()\n",
    "    ])\n",
    "    return valid_transform\n",
    "\n",
    "\n",
    "def get_datasets_3(pretrained=True):\n",
    "    dataset_test_valTF = datasets.ImageFolder(\n",
    "        base_path+\"/data/test\", \n",
    "        transform=(get_valid_transform_3(pretrained=True))\n",
    "    )\n",
    "    \n",
    "    dataset_test_trainTF = datasets.ImageFolder(\n",
    "        base_path+\"/data/test\", \n",
    "        transform=(get_train_transform_3(pretrained=True))\n",
    "    )\n",
    "    return dataset_test_valTF, dataset_test_trainTF\n",
    "\n",
    "\n",
    "def get_data_loaders_3(dataset_test_valTF, dataset_test_trainTF, BATCH_SIZE=8):\n",
    "    test_loader_valTF  = DataLoader(dataset_test_valTF, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader_trainTF  = DataLoader(dataset_test_trainTF, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return test_loader_valTF, test_loader_trainTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e8c7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_valTF_3, dataset_test_trainTF_3 = get_datasets_3(True)\n",
    "test_loader_valTF_3, test_loader_trainTF_3 = get_data_loaders_3(dataset_test_valTF_3, dataset_test_trainTF_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "967a76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_3 = base_path+f\"/efficientnet_b4_randomweight/model_checkpoint_{17}.pt\"\n",
    "model_3 = torch.load(PATH_3, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e7ff771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,008,909 total parameters.\n",
      "460,293 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params_3 = sum(p.numel() for p in model_3.parameters())\n",
    "print(f\"{total_params_3:,} total parameters.\")\n",
    "total_trainable_params_3 = sum(\n",
    "    p.numel() for p in model_3.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params_3:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4d2d5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [02:45<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [03:48<00:00,  4.97s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_3a, accuracy_3a, balanced_acc_3a, list_true_3a, list_pred_3a = validate(model_3, test_loader_valTF_3, criterion)\n",
    "loss_3b, accuracy_3b, balanced_acc_3b, list_true_3b, list_pred_3b = validate(model_3, test_loader_trainTF_3, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d56a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "cks_3a = cohen_kappa_score(list_true_3a, list_pred_3a)\n",
    "cks_3b = cohen_kappa_score(list_true_3b, list_pred_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "65f47b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Only Resizing of images\n",
      " Test loss: 0.583\n",
      " Test acc: 80.601\n",
      " Test BACC: 0.578\n",
      " Kappa-Cohen: 0.687\n",
      "With Training Image preprocessing\n",
      " Test loss: 0.612\n",
      " Test acc: 79.235\n",
      " Test BACC: 0.549\n",
      " Kappa-Cohen: 0.664\n"
     ]
    }
   ],
   "source": [
    "print(f\"With Only Resizing of images\\n Test loss: {loss_3a:.3f}\\n Test acc: {accuracy_3a:.3f}\\n Test BACC: {balanced_acc_3a:.3f}\\n Kappa-Cohen: {cks_3a:.3f}\")\n",
    "print(f\"With Training Image preprocessing\\n Test loss: {loss_3b:.3f}\\n Test acc: {accuracy_3b:.3f}\\n Test BACC: {balanced_acc_3b:.3f}\\n Kappa-Cohen: {cks_3b:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49abd6d2",
   "metadata": {},
   "source": [
    "### Model 4: Data Augmentation + EfficientNet_b4\n",
    "(1) Loading model with highest Training BACC: epoch 12 -> model_checkpoint_11\n",
    "\n",
    "(2) Loading model with highest Validation BACC: epoch 18 -> model_checkpoint_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb5f891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform_4(pretrained=True):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "        transforms.ColorJitter(brightness=(1.4, 1.6), contrast=(1.5,2)),\n",
    "        transforms.Resize((380, 380)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize_transform()\n",
    "    ])\n",
    "    return train_transform\n",
    "\n",
    "\n",
    "def get_valid_transform_4(pretrained=True):\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.Resize((380, 380)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize_transform()\n",
    "    ])\n",
    "    return valid_transform\n",
    "\n",
    "\n",
    "def get_datasets_4(pretrained=True):\n",
    "    dataset_test_valTF = datasets.ImageFolder(\n",
    "        base_path+\"/data/test\", \n",
    "        transform=(get_valid_transform_4(pretrained=True))\n",
    "    )\n",
    "    \n",
    "    dataset_test_trainTF = datasets.ImageFolder(\n",
    "        base_path+\"/data/test\", \n",
    "        transform=(get_train_transform_4(pretrained=True))\n",
    "    )\n",
    "    return dataset_test_valTF, dataset_test_trainTF\n",
    "\n",
    "\n",
    "def get_data_loaders_4(dataset_test_valTF, dataset_test_trainTF, BATCH_SIZE=8):\n",
    "    test_loader_valTF  = DataLoader(dataset_test_valTF, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader_trainTF  = DataLoader(dataset_test_trainTF, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    return test_loader_valTF, test_loader_trainTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfdf29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_valTF_4, dataset_test_trainTF_4 = get_datasets_4(True)\n",
    "test_loader_valTF_4, test_loader_trainTF_4 = get_data_loaders_4(dataset_test_valTF_4, dataset_test_trainTF_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66964400",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_4 = base_path+f\"/efficientnet_b4_dup_augData/model_checkpoint_{11}.pt\"\n",
    "model_4 = torch.load(PATH_4, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed2b94a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,008,909 total parameters.\n",
      "460,293 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params_4 = sum(p.numel() for p in model_4.parameters())\n",
    "print(f\"{total_params_4:,} total parameters.\")\n",
    "total_trainable_params_4 = sum(\n",
    "    p.numel() for p in model_4.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params_4:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f8f19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [02:48<00:00,  3.67s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_4a, accuracy_4a, balanced_acc_4a, list_true_4a, list_pred_4a = validate(model_4, test_loader_valTF_4, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "224f832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [03:56<00:00,  5.14s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_4b, accuracy_4b, balanced_acc_4b, list_true_4b, list_pred_4b = validate(model_4, test_loader_trainTF_4, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95a03b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cks_4a = cohen_kappa_score(list_true_4a, list_pred_4a)\n",
    "cks_4b = cohen_kappa_score(list_true_4b, list_pred_4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74186f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Only Resizing of images\n",
      " Test loss: 14.171\n",
      " Test acc: 9.016\n",
      " Test BACC: 0.200\n",
      " Cohen-Kappa: 0.000\n",
      "With Training Image preprocessing\n",
      " Test loss: 13.189\n",
      " Test acc: 9.290\n",
      " Test BACC: 0.201\n",
      " Cohen-Kappa: 0.002\n"
     ]
    }
   ],
   "source": [
    "print(f\"With Only Resizing of images\\n Test loss: {loss_4a:.3f}\\n Test acc: {accuracy_4a:.3f}\\n Test BACC: {balanced_acc_4a:.3f}\\n Cohen-Kappa: {cks_4a:.3f}\")\n",
    "print(f\"With Training Image preprocessing\\n Test loss: {loss_4b:.3f}\\n Test acc: {accuracy_4b:.3f}\\n Test BACC: {balanced_acc_4b:.3f}\\n Cohen-Kappa: {cks_4b:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64bc289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_5 = base_path+f\"/efficientnet_b4_dup_augData/model_checkpoint_{17}.pt\"\n",
    "model_5 = torch.load(PATH_5, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f12a2c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,008,909 total parameters.\n",
      "460,293 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params_5 = sum(p.numel() for p in model_5.parameters())\n",
    "print(f\"{total_params_5:,} total parameters.\")\n",
    "total_trainable_params_5 = sum(\n",
    "    p.numel() for p in model_5.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params_5:,} training parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd9fda0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [02:58<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_5a, accuracy_5a, balanced_acc_5a, list_true_5a, list_pred_5a = validate(model_5, test_loader_valTF_4, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65e3265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [03:57<00:00,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_5b, accuracy_5b, balanced_acc_5b, list_true_5b, list_pred_5b = validate(model_5, test_loader_trainTF_4, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "efe80f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cks_5a = cohen_kappa_score(list_true_5a, list_pred_5a)\n",
    "cks_5b = cohen_kappa_score(list_true_5b, list_pred_5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d975d0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Only Resizing of images\n",
      " Test loss: 10.200\n",
      " Test acc: 9.016\n",
      " Test BACC: 0.200\n",
      " Cohen-Kappa: 0.000\n",
      "With Training Image preprocessing\n",
      " Test loss: 9.333\n",
      " Test acc: 10.929\n",
      " Test BACC: 0.207\n",
      " Cohen-Kappa: 0.012\n"
     ]
    }
   ],
   "source": [
    "print(f\"With Only Resizing of images\\n Test loss: {loss_5a:.3f}\\n Test acc: {accuracy_5a:.3f}\\n Test BACC: {balanced_acc_5a:.3f}\\n Cohen-Kappa: {cks_5a:.3f}\")\n",
    "print(f\"With Training Image preprocessing\\n Test loss: {loss_5b:.3f}\\n Test acc: {accuracy_5b:.3f}\\n Test BACC: {balanced_acc_5b:.3f}\\n Cohen-Kappa: {cks_5b:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5f060",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "181edfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30.601092896174865, 0.27199961946310325, 0.10526366444981272)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_1a, balanced_acc_1a, cks_1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9437142d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.60109289617486, 0.5783530783180146, 0.6869533791109506)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_3a, balanced_acc_3a, cks_3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c358e0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4124462792589929"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel([accuracy_1a, balanced_acc_1a, cks_1a], [accuracy_3a, balanced_acc_3a, cks_3a]).pvalue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
