{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c96b3617",
   "metadata": {},
   "source": [
    "### Data Augmentation because of high class imbalance\n",
    "Ref: https://github.com/enrico310786/brain_tumor_classification/blob/master/augment_train_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48939822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1a125dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f644fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not Used\n",
    "transform_old = A.Compose([\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.RandomGamma(p=0.5),\n",
    "    A.Rotate(p=0.5),\n",
    "    A.MultiplicativeNoise(multiplier=[0.5, 1.5], elementwise=True, per_channel=True, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, rotate_limit=45, p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424b5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    #A.HueSaturationValue(p=0.5),\n",
    "    #A.RandomBrightnessContrast(p=0.5),\n",
    "    A.RandomGamma(gamma_limit=[80,120], p=0.5),\n",
    "    A.Sharpen(p=0.7),\n",
    "    A.Rotate(limit=[-15,15], p=0.5),\n",
    "    A.MultiplicativeNoise(multiplier=[0.5, 1.5], p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc5571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_create_dir(path_dir):\n",
    "\n",
    "    CHECK_FOLDER = os.path.isdir(path_dir)\n",
    "    if CHECK_FOLDER:\n",
    "        print(\"The directory '{}' exists. Deleting\".format(path_dir))\n",
    "        try:\n",
    "            shutil.rmtree(path_dir)\n",
    "        except OSError as e:\n",
    "            print(\"Error: {}\".format(e.strerror))\n",
    "            raise e\n",
    "\n",
    "        CHECK_FOLDER = os.path.isdir(path_dir)\n",
    "        if not CHECK_FOLDER:\n",
    "            print(\"Creating directory '{}'\".format(path_dir))\n",
    "            os.makedirs(path_dir)\n",
    "    else:\n",
    "        print(\"Creating directory '{}'\".format(path_dir))\n",
    "        os.makedirs(path_dir)\n",
    "\n",
    "\n",
    "def make_data_augmentation(path_original_dataset, path_augmented_dataset, root_csv, final_number, df, class2label):\n",
    "\n",
    "    #iter over directory\n",
    "    for subdir, dirs, files in os.walk(path_original_dataset):\n",
    "        for classe in dirs:\n",
    "            path_class = os.path.join(path_original_dataset, classe)\n",
    "            CHECK_FOLDER = os.path.isdir(path_class)\n",
    "            if CHECK_FOLDER:\n",
    "                label = class2label[classe]\n",
    "                print(\"CLASS: {}  - LABEL: {}\".format(classe, label))\n",
    "                number_files = len(os.listdir(path_class))\n",
    "                print(\"number of files in directory '{}': {}\".format(path_class, number_files))\n",
    "\n",
    "                path_directory_save = os.path.join(path_augmented_dataset, classe)\n",
    "                path_directory_save_for_csv = os.path.join(root_csv, classe)\n",
    "                CHECK_FOLDER = os.path.isdir(path_directory_save)\n",
    "                if not CHECK_FOLDER:\n",
    "                    print(\"Create directory '{}'\".format(path_directory_save))\n",
    "                    os.makedirs(path_directory_save)\n",
    "\n",
    "                #determino il numero di volte per cui devo applicare la trasformazione su una singola immagine\n",
    "\n",
    "                n_applications = round((final_number-number_files)/number_files)\n",
    "                if n_applications < 0:\n",
    "                    n_applications = 0\n",
    "                print('n_applications: ', n_applications)\n",
    "\n",
    "                for filename in os.listdir(path_class):\n",
    "                    path_image = os.path.join(path_class, filename)\n",
    "                    image = cv2.imread(path_image)\n",
    "                    filename_no_ext, extension= filename.split(\".\")[0], filename.split(\".\")[-1]\n",
    "\n",
    "                    # copy the original image from the sourse dir to the dest dir\n",
    "                    dst_file = os.path.join(path_directory_save, filename)\n",
    "                    shutil.copy2(path_image, dst_file)\n",
    "\n",
    "                    df_temp = pd.DataFrame({'CLASS': [classe],\n",
    "                                    'PATH': os.path.join(path_directory_save_for_csv, filename),\n",
    "                                    'LABEL': [label]})\n",
    "                    df = pd.concat([df, df_temp], ignore_index=True)\n",
    "\n",
    "                    for i in range(n_applications):\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                        augmented_image = transform(image=image)['image']\n",
    "                        augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "                        new_file_name = filename_no_ext + '_' + str(i+1) + '.' + extension\n",
    "                        dst_file = os.path.join(path_directory_save, new_file_name)\n",
    "\n",
    "                        cv2.imwrite(dst_file, augmented_image)\n",
    "                        df_temp = pd.DataFrame({'CLASS': [classe],\n",
    "                                        'PATH': os.path.join(path_directory_save_for_csv, new_file_name),\n",
    "                                        'LABEL': [label]})\n",
    "                        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "\n",
    "                number_file_aumentati = len(os.listdir(path_directory_save))\n",
    "                print(\"Final number of files in directory '{}': {}\".format(path_directory_save, number_file_aumentati))\n",
    "                print(\"---------------------------------------------\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d7a59f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented' esiste. La cancello\n",
      "Creo la directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented'\n",
      "Data augmentation\n",
      "Train set\n",
      "CLASS: 0  - LABEL: 0\n",
      "number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data/train\\0': 1434\n",
      "Create dir directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\0'\n",
      "n_applications:  0\n",
      "Final number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\0': 1434\n",
      "---------------------------------------------\n",
      "CLASS: 1  - LABEL: 1\n",
      "number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data/train\\1': 300\n",
      "Create dir directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\1'\n",
      "n_applications:  4\n",
      "Final number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\1': 1500\n",
      "---------------------------------------------\n",
      "CLASS: 2  - LABEL: 2\n",
      "number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data/train\\2': 808\n",
      "Create dir directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\2'\n",
      "n_applications:  1\n",
      "Final number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\2': 1616\n",
      "---------------------------------------------\n",
      "CLASS: 3  - LABEL: 3\n",
      "number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data/train\\3': 154\n",
      "Create dir directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\3'\n",
      "n_applications:  10\n",
      "Final number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\3': 1694\n",
      "---------------------------------------------\n",
      "CLASS: 4  - LABEL: 4\n",
      "number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data/train\\4': 234\n",
      "Create dir directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\4'\n",
      "n_applications:  6\n",
      "Final number of files in directory 'C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/data_augmented/train_augmented\\4': 1638\n",
      "---------------------------------------------\n",
      "df_train info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7882 entries, 0 to 7881\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   CLASS   7882 non-null   object\n",
      " 1   PATH    7882 non-null   object\n",
      " 2   LABEL   7882 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 184.9+ KB\n",
      "None\n",
      "-------------------------------------------------------------\n",
      "df_train:  CLASS values count\n",
      "CLASS\n",
      "3        1694\n",
      "4        1638\n",
      "2        1616\n",
      "1        1500\n",
      "0        1434\n",
      "Name: count, dtype: int64\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "FINAL_NUMBER_SAMPLES_PER_CLASSES = 1617\n",
    "base_path = \"C:/Users/anush/OneDrive/Documents/Sem3/AI in Health Technology/Project/\"\n",
    "path_dataset_train = base_path + \"data/train\"\n",
    "path_augmented_dataset_train = base_path + \"data_augmented/train_augmented\"\n",
    "path_augmented_csv_train = base_path + \"data_augmented/train_augmented.csv\"\n",
    "df_train_augmented = pd.DataFrame(columns=['CLASS', 'PATH', 'LABEL'])\n",
    "root_csv = \"train_augmented\"\n",
    "\n",
    "# the list of classes has to be on the same order as the original dataset\n",
    "list_classes = ['0', '1', '2', '3', '4']\n",
    "class2label = {k: v for (v, k) in enumerate(list_classes)}\n",
    "\n",
    "# 1 - clean and create the dataset directory\n",
    "clean_create_dir(path_augmented_dataset_train)\n",
    "\n",
    "# 2 - make data augmentation\n",
    "print(\"Data augmentation\")\n",
    "print(\"Train set\")\n",
    "df_train = make_data_augmentation(path_dataset_train, path_augmented_dataset_train, root_csv, FINAL_NUMBER_SAMPLES_PER_CLASSES, df_train_augmented, class2label)\n",
    "\n",
    "# 3 - create new csv\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_train.to_csv(path_augmented_csv_train, index=False)\n",
    "print(\"df_train info\")\n",
    "print(df_train.info())\n",
    "print('-------------------------------------------------------------')\n",
    "print(\"df_train:  CLASS values count\")\n",
    "print(df_train[[\"CLASS\"]].value_counts())\n",
    "print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b884a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
